{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/전국_교통사고_민원포함_긍부정요인완료_1017.csv\")\n",
    "\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"꼬리물기_민원건수\",\"불법유턴_민원건수\",\"불법좌회전_민원건수\",\"신호위반_민원건수\",\"역주행_민원건수\",\"정지선침범_민원건수\",\"중앙선침범_민원건수\",\"지정차로위반_민원건수\",\"진로변경방법위반_민원건수\",\"민원_전체건수\",\"법규위반_안전운전불이행_건수\",\"법규위반_보행자보호의무위반_건수\",\"법규위반_신호위반_건수\",\"법규위반_교차로운행방법위반_건수\",\"법규위반_중앙선침범_건수\",\"법규위반_직진우회전진행방해_건수\",\"법규위반_불법유턴_건수\",\"법규위반_안전거리미확보_건수\",\"법규위반_기타_건수\",\"법규위반_차로위반_건수\",\"노면상태_건조_건수\",\"노면상태_서리결빙_건수\",\"노면상태_젖음습기_건수\",\"노면상태_적설_건수\",\"노면상태_기타_건수\",\"기상상태_맑음_건수\",\"기상상태_흐림_건수\",\"기상상태_비_건수\",\"기상상태_안개_건수\",\"기상상태_눈_건수\",\"기상상태_기타_건수\",\"도로형태_교차로안_건수\",\"도로형태_교차로부근_건수\",\"도로형태_교차로횡단보도내_건수\",\"도로형태_교량_건수\",\"도로형태_터널_건수\",\"도로형태_지하차도_건수\",\"도로형태_단일로_기타_건수\",\"도로형태_주차장_건수\"\n"
     ]
    }
   ],
   "source": [
    "# data_string = \"꼬리물기_민원건수,불법유턴_민원건수,불법좌회전_민원건수,신호위반_민원건수,역주행_민원건수,정지선침범_민원건수,중앙선침범_민원건수,지정차로위반_민원건수,진로변경방법위반_민원건수,민원_전체건수,법규위반_안전운전불이행_건수,법규위반_보행자보호의무위반_건수,법규위반_신호위반_건수,법규위반_교차로운행방법위반_건수,법규위반_중앙선침범_건수,법규위반_직진우회전진행방해_건수,법규위반_불법유턴_건수,법규위반_안전거리미확보_건수,법규위반_기타_건수,법규위반_차로위반_건수,노면상태_건조_건수,노면상태_서리결빙_건수,노면상태_젖음습기_건수,노면상태_적설_건수,노면상태_기타_건수,기상상태_맑음_건수,기상상태_흐림_건수,기상상태_비_건수,기상상태_안개_건수,기상상태_눈_건수,기상상태_기타_건수,도로형태_교차로안_건수,도로형태_교차로부근_건수,도로형태_교차로횡단보도내_건수,도로형태_교량_건수,도로형태_터널_건수,도로형태_지하차도_건수,도로형태_단일로_기타_건수,도로형태_주차장_건수\"\n",
    "\n",
    "# # Split the string into a list of strings\n",
    "# data_list = data_string.split(',')\n",
    "\n",
    "# # Add double quotes around each item in the list and join them back into a single string\n",
    "# quoted_data_string = ','.join(f'\"{item}\"' for item in data_list)\n",
    "\n",
    "# print(quoted_data_string)\n",
    "\n",
    "# # \"꼬리물기_민원건수\",\"불법유턴_민원건수\",\"불법좌회전_민원건수\",\"신호위반_민원건수\",\"역주행_민원건수\",\"정지선침범_민원건수\",\"중앙선침범_민원건수\",\"지정차로위반_민원건수\",\"진로변경방법위반_민원건수\",\"민원_전체건수\",\"법규위반_안전운전불이행_건수\",\"법규위반_보행자보호의무위반_건수\",\"법규위반_신호위반_건수\",\"법규위반_교차로운행방법위반_건수\",\"법규위반_중앙선침범_건수\",\"법규위반_직진우회전진행방해_건수\",\"법규위반_불법유턴_건수\",\"법규위반_안전거리미확보_건수\",\"법규위반_기타_건수\",\"법규위반_차로위반_건수\",\"노면상태_건조_건수\",\"노면상태_서리결빙_건수\",\"노면상태_젖음습기_건수\",\"노면상태_적설_건수\",\"노면상태_기타_건수\",\"기상상태_맑음_건수\",\"기상상태_흐림_건수\",\"기상상태_비_건수\",\"기상상태_안개_건수\",\"기상상태_눈_건수\",\"기상상태_기타_건수\",\"도로형태_교차로안_건수\",\"도로형태_교차로부근_건수\",\"도로형태_교차로횡단보도내_건수\",\"도로형태_교량_건수\",\"도로형태_터널_건수\",\"도로형태_지하차도_건수\",\"도로형태_단일로_기타_건수\",\"도로형태_주차장_건수\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 csv파일 생성\n",
    "#시군구_읍면동명 = '신설동'인 csv파일 생성\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/전국_교통사고_민원포함_긍부정요인완료_1017.csv\",encoding='utf-8')\n",
    "\n",
    "# '시군구_읍면동명' 컬럼이 '신설동'인 로우만 선택\n",
    "df_sinsul = df[df['시군구_읍면동명'] == '신설동']\n",
    "\n",
    "# 선택한 데이터를 CSV 파일로 저장\n",
    "# df_sinsul.to_csv('sinsul.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # from statsmodels.tsa.arima.model import ARIMA\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# # 데이터 로드\n",
    "# # df = pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/전국_교통사고_민원포함_긍부정요인완료_1017.csv\",encoding='utf-8')\n",
    "\n",
    "# df = pd.read_csv('/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/code/pages/sinsul.csv',encoding='utf-8')\n",
    "\n",
    "# # '사고일시_월' 컬럼을 datetime 형태로 변환\n",
    "# df['사고일시_월'] = pd.to_datetime(df['사고일시_월'], format='%m월')\n",
    "\n",
    "\n",
    "# # 월별로 데이터를 그룹화하고 합계 계산\n",
    "# df_grouped = df.groupby('사고일시_월').sum()\n",
    "\n",
    "# # 오류 데이터 타입확인\n",
    "# print(df_grouped.dtypes)\n",
    "\n",
    "# # 2023년 예측 결과를 저장할 DataFrame 생성\n",
    "# df_pred = pd.DataFrame()\n",
    "\n",
    "# for column in df_grouped.columns:\n",
    "#     try:\n",
    "#         # 정수형(int)로 변환하여 예측 수행\n",
    "#         model = SARIMAX(df_grouped[column].astype(int), order=(1,1,0), seasonal_order=(1,1,0,12))\n",
    "#         model_fit = model.fit(method_kwargs={\"warn_convergence\": False})\n",
    "        \n",
    "#         # 2023년 1월부터 12월까지 예측 (12개월)\n",
    "#         forecast_result = model_fit.forecast(steps=12)\n",
    "        \n",
    "#         # 결과 저장 (예측값만 저장)\n",
    "#         df_pred[column] = forecast_result[0]\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error with column {column}: {e}\")\n",
    "# # 이 부분 추가: 각 컬럼별로 몇 개의 데이터가 있는지 확인\n",
    "# print(df_pred.count())\n",
    "\n",
    "# # 인덱스 설정 (2023년 1월 ~ 12월)\n",
    "# if not df_pred.empty:\n",
    "#     df_pred.index = pd.date_range(start='2023-01-01', periods=12, freq='M').strftime('%Y년 %m월')\n",
    "#     # CSV 파일로 저장\n",
    "#     df_pred.to_csv('2023_forecast_ver1.csv')\n",
    "# else:\n",
    "#     print(\"No data to save.\")\n",
    "# print('end')\n",
    "# # 실행 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# # 데이터 불러오기 및 전처리\n",
    "# df = pd.read_csv('/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/code/pages/sinsul.csv',encoding='utf-8') # 'your_data.csv'를 실제 데이터 파일 경로로 바꿔주세요.\n",
    "# df['사고일시_월'] = pd.to_datetime(df['사고일시_월'], format='%Y년%m월')\n",
    "\n",
    "# # 예측할 칼럼들 리스트\n",
    "# pred_cols = ['꼬리물기_민원건수', '불법유턴_민원건수', '불법좌회전_민원건수', \n",
    "#              '신호위반_민원건수', '역주행_민원건수', \n",
    "#              '정지선침범_민원건수','중앙선침범_민원건수',\n",
    "#              '지정차로위반_민원건수','진로변경방법위반_민원건수']\n",
    "\n",
    "# results = []  # 결과를 저장할 리스트\n",
    "\n",
    "# for region in df['시군구_읍면동명'].unique():\n",
    "#     print(f\"Processing {region}...\")\n",
    "    \n",
    "#     for col in pred_cols:\n",
    "#         # 해당 지역과 칼럽에 대한 데이터만 추출\n",
    "#         temp_df = df[df['시군구읍면동명'] == region][['사고일시월', col]].sort_values(by='사고일시월')\n",
    "        \n",
    "#         X_train, y_train = temp_df[:-1], temp_df[1:]\n",
    "        \n",
    "#         # LSTM 모델에 맞게 차원 변환 (samples, timesteps, features)\n",
    "#         X_train = np.array(X_train).reshape(-1, 1, 1)\n",
    "#         y_train = np.array(y_train).reshape(-1, 1)\n",
    "        \n",
    "#         # LSTM 모델 정의 및 학습\n",
    "#         model = Sequential()\n",
    "#         model.add(LSTM(50, activation='relu', input_shape=(None, 1)))\n",
    "#         model.add(Dense(1))\n",
    "        \n",
    "#         model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "#         model.fit(X_train,y_train , epochs=200)\n",
    "\n",
    "#         for month in range(1,13):   # 각 월별 예측 수행  \n",
    "#             x_input=np.array(month).reshape(-1, 1 ,1)   # 입력 형태 맞춤  \n",
    "#             yhat = model.predict(x_input)  # 예측 수행\n",
    "#             results.append([region, f\"2023년{month}월\", yhat[0][0]])   # 결과 저장\n",
    "            \n",
    "# # 결과를 데이터프레임으로 변환 및 저장\n",
    "# result_df = pd.DataFrame(results, columns=['시군구_읍면동명', '사고일시_월', '예측값'])\n",
    "# result_df.to_csv('prediction_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/도로교통공단_전국_일자별_교통사고데이터_1003.csv\",encoding=\"utf-8\")\n",
    "df['사고일시'] = pd.to_datetime(df['사고일시'], format='%Y년 %m월 %d일 %H시')\n",
    "df['사고일시'] = df['사고일시'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 칼럼명 변경\n",
    "df = df.rename(columns={'사고일시': 'date'})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv('도로교통공단_전국_일자별_교통사고데이터.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/민원데이터_전체통합_주소완료_1003.csv\",encoding=\"utf-8\")\n",
    "\n",
    "# 세종특별자치시는 필터링\n",
    "df = df[df['시도명'] != '세종특별자치시']\n",
    "# 위도, 경도 칼럼은 삭제\n",
    "df = df.drop(columns=['위도', '경도'])\n",
    "\n",
    "# 데이터프레임에서 결측값이 있는 로우를 제거\n",
    "df = df.dropna(subset=['시도명'])\n",
    "\n",
    "# 칼럼명 변경\n",
    "df = df.rename(columns={'발생일': 'date'})\n",
    "\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv('민원데이터_전체통합_교통사고데이터.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271267 entries, 0 to 271266\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   발생일      271267 non-null  object \n",
      " 1   위도       271267 non-null  float64\n",
      " 2   경도       271267 non-null  float64\n",
      " 3   신고유형     271267 non-null  object \n",
      " 4   ADDRESS  271203 non-null  object \n",
      " 5   시도명      271203 non-null  object \n",
      " 6   시군구명     268550 non-null  object \n",
      " 7   읍면동명     271203 non-null  object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 16.6+ MB\n",
      "아래는 필터링 데이터\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268550 entries, 0 to 268549\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   date     268550 non-null  object\n",
      " 1   신고유형     268550 non-null  object\n",
      " 2   ADDRESS  268550 non-null  object\n",
      " 3   시도명      268550 non-null  object\n",
      " 4   시군구명     268550 non-null  object\n",
      " 5   읍면동명     268550 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "df = pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/code/pages/민원데이터_전체통합_교통사고데이터.csv\",encoding=\"utf-8\")\n",
    "\n",
    "df1= pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/민원데이터_전체통합_주소완료_1003.csv\",encoding=\"utf-8\")\n",
    "\n",
    "df1.info()\n",
    "print(\"아래는 필터링 데이터\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['꼬리물기' '불법유턴' '불법좌회전' '신호위반' '역주행' '정지선침범' '중앙선침범' '지정차로위반' '진로변경방법위반']\n",
      "['대전광역시' '부산광역시' '경기도' '대구광역시' '전라남도' '서울특별시' '경상남도' '충청북도' '인천광역시' '전라북도'\n",
      " '광주광역시' '경상북도' '제주특별자치도' '울산광역시' '강원특별자치도' '충청남도']\n",
      "-----\n",
      "0\n",
      "0\n",
      "-----\n",
      "268550\n",
      "-----\n",
      "신고유형      시도명    \n",
      "꼬리물기      경기도         925\n",
      "          서울특별시       409\n",
      "          부산광역시       210\n",
      "          대전광역시       172\n",
      "          대구광역시       145\n",
      "                     ... \n",
      "진로변경방법위반  전라북도       1690\n",
      "          전라남도       1297\n",
      "          울산광역시      1017\n",
      "          강원특별자치도     982\n",
      "          제주특별자치도     432\n",
      "Name: 시도명, Length: 144, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print(df['신고유형'].unique())\n",
    "# print(df['시도명'].unique())\n",
    "# print(\"-----\")\n",
    "# print(df['신고유형'].isnull().sum())\n",
    "# print(df['시도명'].isnull().sum())\n",
    "# print(\"-----\")\n",
    "# print(df.dropna(subset=['신고유형', '시도명']).shape[0])\n",
    "# print(\"-----\")\n",
    "# print(df.groupby('신고유형')['시도명'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 액셀 파일 경로\n",
    "# excel_file = '/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/불법좌회전.xlsx'\n",
    "# excel_file = '/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/신호위반.xlsx'\n",
    "# excel_file = '/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/역주행.xlsx'\n",
    "# excel_file = '/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/정지선침범.xlsx'\n",
    "excel_file = '/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/중앙선침범.xlsx'\n",
    "# excel_file = '/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/지정차로위반.xlsx'\n",
    "\n",
    "# CSV 파일 경로\n",
    "csv_file = '/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/data/제3회민원데이터분석경진대회_모의데이터/csv/중앙선침범.csv'\n",
    "\n",
    "# 액셀 파일 불러오기\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv(csv_file, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/code/pages/민원데이터_전체통합_교통사고데이터.csv\",encoding=\"utf-8\")\n",
    "\n",
    "# pivot_table 생성\n",
    "pivot_df = pd.pivot_table(df, index=['date', 'ADDRESS', '시도명', '시군구명', '읍면동명'], columns='신고유형', aggfunc='size', fill_value=0).reset_index()\n",
    "\n",
    "# 칼럼 순서 조정\n",
    "pivot_df = pivot_df[['date','ADDRESS','시도명','시군구명','읍면동명',\n",
    "                     '꼬리물기', '불법유턴', '불법좌회전',\n",
    "                     '신호위반', '역주행',\n",
    "                     '정지선침범' ,  '중앙선침범',\n",
    "                     '지정차로위반' ,  '진로변경방법위반']]\n",
    "\n",
    "# CSV 파일로 저장\n",
    "pivot_df.to_csv('민원데이터_사고일자통합.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/code/pages/민원데이터_사고일자통합.csv\",encoding=\"utf-8\")\n",
    "# \"시도명\"이 \"서울특별시\"인 행만 선택\n",
    "dejun_df = df[df['시도명'] == '대전광역시']\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "dejun_df.to_csv('민원데이터_대전광역시.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # 경고 메세지 숨기기\n",
    "\n",
    "# 데이터 로드 (파일 경로는 실제 CSV 파일이 위치한 Google Drive 내의 경로로 변경하세요)\n",
    "df = pd.read_csv('/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/code/pages/민원데이터_대전광역시.csv', encoding=\"utf-8\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# ADDRESS와 사고 유형 리스트 생성\n",
    "addresses = df['ADDRESS'].unique()\n",
    "accident_types = ['꼬리물기', '불법유턴', '불법좌회전', '신호위반',\n",
    "                  '역주행', '정지선침범', '중앙선침범',\n",
    "                  '지정차로위반','진로변경방법위반']\n",
    "\n",
    "# 결과를 저장할 빈 데이터프레임 생성\n",
    "final_future_pred = pd.DataFrame()\n",
    "\n",
    "for address in addresses:\n",
    "    for accident_type in accident_types:\n",
    "        temp_df = df[df['ADDRESS'] == address][['date', accident_type]].set_index('date').sort_index()\n",
    "        \n",
    "        # 전체 기간 동안의 일자 인덱스 생성 \n",
    "        all_dates = pd.date_range(start=temp_df.index.min(), end='2023-12-31')\n",
    "        \n",
    "        # 일자 인덱스를 사용하여 DataFrame 재색인화 (누락된 날짜 값은 NaN으로 설정)\n",
    "        temp_df_reindexed = temp_df.reindex(all_dates)\n",
    "        \n",
    "        # NaN 값을 0으로 채우기 \n",
    "        temp_df_reindexed.fillna(0, inplace=True)\n",
    "\n",
    "        best_aic = np.inf \n",
    "        best_order = None\n",
    "\n",
    "        # p, d, q 값 범위 설정\n",
    "        p_range = range(3)\n",
    "        d_range = range(3)\n",
    "        q_range = range(3)\n",
    "\n",
    "         # Grid Search to find optimal parameters for ARIMA model.\n",
    "        for p in p_range:\n",
    "            for d in d_range:\n",
    "                for q in q_range:\n",
    "                    try:\n",
    "                        temp_model_fit=ARIMA(temp_df_reindexed, order=(p,d,q)).fit(disp=0)    \n",
    "                        if temp_model_fit.aic < best_aic:  \n",
    "                            best_aic=temp_model_fit.aic    \n",
    "                            best_order=(p,d,q)    \n",
    "                    except: \n",
    "                        continue\n",
    "\n",
    "        # If no valid (p,d,q) combination is found use (0, 0, 0)\n",
    "        if best_order is None:\n",
    "            best_order = (0, 0 , 0)\n",
    "\n",
    "        # Best ARIMA model fit\n",
    "        model = ARIMA(temp_df_reindexed[accident_type], order=best_order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        future_dates=[temp_df_reindexed.index[-1] + DateOffset(days=x) for x in range(1,366)]\n",
    "        future_dates_df=pd.DataFrame(index=future_dates[0:],columns=temp_df.columns)\n",
    "\n",
    "        future_prediction=pd.concat([temp_df_reindexed,future_dates_df])\n",
    "\n",
    "        future_prediction[accident_type]=model_fit.predict(start=future_prediction.index[future_prediction.shape[0]-365],\n",
    "                                                          end=future_prediction.index[-1])\n",
    "        \n",
    "        # ADDRESS와 사고 유형 칼럼 추가 및 결합\n",
    "        future_prediction.reset_index(inplace=True)\n",
    "        future_prediction.rename(columns={'index': 'date'}, inplace=True)\n",
    "        future_prediction.insert(1,'ADDRESS',[address]*len(future_prediction))\n",
    "       \n",
    "        final_future_pred = pd.concat([final_future_pred,future_prediction],ignore_index=True)\n",
    "\n",
    "# 결과 저장\n",
    "final_future_pred.to_csv('민원데이터_사고일자통합_대전광역시_prediction_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksy/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/ksy/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/ksy/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/ksy/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'The `start` argument could not be matched to a location related to the index of the data.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:548\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1672531200000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:516\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:550\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2023-01-01 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/datetimes.py:736\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49mget_loc(\u001b[39mself\u001b[39;49m, key, method, tolerance)\n\u001b[1;32m    737\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2023-01-01 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:249\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[0;34m(key, index, row_labels)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39minteger)):\n\u001b[0;32m--> 249\u001b[0m     loc \u001b[39m=\u001b[39m row_labels\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/datetimes.py:738\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 738\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(orig_key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2023-01-01'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:358\u001b[0m, in \u001b[0;36mget_prediction_index\u001b[0;34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     start, _, start_oos \u001b[39m=\u001b[39m get_index_label_loc(\n\u001b[1;32m    359\u001b[0m         start, base_index, data\u001b[39m.\u001b[39;49mrow_labels\n\u001b[1;32m    360\u001b[0m     )\n\u001b[1;32m    361\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:281\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[0;34m(key, index, row_labels)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    282\u001b[0m \u001b[39mreturn\u001b[39;00m loc, index, index_was_expanded\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:245\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[0;34m(key, index, row_labels)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     loc, index, index_was_expanded \u001b[39m=\u001b[39m get_index_loc(key, index)\n\u001b[1;32m    246\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:195\u001b[0m, in \u001b[0;36mget_index_loc\u001b[0;34m(key, index)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mstr\u001b[39m(e))\n\u001b[1;32m    196\u001b[0m loc \u001b[39m=\u001b[39m key\n",
      "\u001b[0;31mKeyError\u001b[0m: 'only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/code/pages/plactice.ipynb 셀 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ksy/%EB%AC%B8%EC%84%9C/%EA%B3%B5%EB%AA%A8%EC%A0%84/%EC%A0%9C3%ED%9A%8C_%EB%AF%BC%EC%9B%90%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/code/pages/plactice.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m future_dates_df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mfuture_dates[\u001b[39m0\u001b[39m:],columns\u001b[39m=\u001b[39mtemp_df\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ksy/%EB%AC%B8%EC%84%9C/%EA%B3%B5%EB%AA%A8%EC%A0%84/%EC%A0%9C3%ED%9A%8C_%EB%AF%BC%EC%9B%90%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/code/pages/plactice.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m future_prediction\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([temp_df,future_dates_df])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ksy/%EB%AC%B8%EC%84%9C/%EA%B3%B5%EB%AA%A8%EC%A0%84/%EC%A0%9C3%ED%9A%8C_%EB%AF%BC%EC%9B%90%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/code/pages/plactice.ipynb#X14sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m future_prediction[accident_type]\u001b[39m=\u001b[39mmodel_fit\u001b[39m.\u001b[39;49mpredict(start\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m2023-01-01\u001b[39;49m\u001b[39m'\u001b[39;49m, end\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m2023-12-31\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ksy/%EB%AC%B8%EC%84%9C/%EA%B3%B5%EB%AA%A8%EC%A0%84/%EC%A0%9C3%ED%9A%8C_%EB%AF%BC%EC%9B%90%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/code/pages/plactice.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# ADDRESS와 사고 유형 칼럼 추가 및 결합\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ksy/%EB%AC%B8%EC%84%9C/%EA%B3%B5%EB%AA%A8%EC%A0%84/%EC%A0%9C3%ED%9A%8C_%EB%AF%BC%EC%9B%90%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/code/pages/plactice.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m future_prediction\u001b[39m.\u001b[39mreset_index(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/wrapper.py:113\u001b[0m, in \u001b[0;36mmake_wrapper.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     obj \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mwrap_output(func(results, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs), how[\u001b[39m0\u001b[39m], how[\u001b[39m1\u001b[39m:])\n\u001b[1;32m    112\u001b[0m \u001b[39melif\u001b[39;00m how:\n\u001b[0;32m--> 113\u001b[0m     obj \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mwrap_output(func(results, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), how)\n\u001b[1;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/mlemodel.py:3487\u001b[0m, in \u001b[0;36mMLEResults.predict\u001b[0;34m(self, start, end, dynamic, information_set, signal_only, **kwargs)\u001b[0m\n\u001b[1;32m   3422\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3423\u001b[0m \u001b[39mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[1;32m   3424\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3484\u001b[0m \u001b[39m    including confidence intervals.\u001b[39;00m\n\u001b[1;32m   3485\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3486\u001b[0m \u001b[39m# Perform the prediction\u001b[39;00m\n\u001b[0;32m-> 3487\u001b[0m prediction_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_prediction(\n\u001b[1;32m   3488\u001b[0m     start, end, dynamic, information_set\u001b[39m=\u001b[39;49minformation_set,\n\u001b[1;32m   3489\u001b[0m     signal_only\u001b[39m=\u001b[39;49msignal_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3490\u001b[0m \u001b[39mreturn\u001b[39;00m prediction_results\u001b[39m.\u001b[39mpredicted_mean\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/statespace/mlemodel.py:3340\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[0;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m     start \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3338\u001b[0m \u001b[39m# Handle start, end, dynamic\u001b[39;00m\n\u001b[1;32m   3339\u001b[0m start, end, out_of_sample, prediction_index \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 3340\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49m_get_prediction_index(start, end, index))\n\u001b[1;32m   3342\u001b[0m \u001b[39m# Handle `dynamic`\u001b[39;00m\n\u001b[1;32m   3343\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dynamic, (\u001b[39mstr\u001b[39m, dt\u001b[39m.\u001b[39mdatetime, pd\u001b[39m.\u001b[39mTimestamp)):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:836\u001b[0m, in \u001b[0;36mTimeSeriesModel._get_prediction_index\u001b[0;34m(self, start, end, index, silent)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[39mGet the location of a specific key in an index or model row labels\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[39msince we have required them to be full indexes, there is no ambiguity).\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    835\u001b[0m nobs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog)\n\u001b[0;32m--> 836\u001b[0m \u001b[39mreturn\u001b[39;00m get_prediction_index(\n\u001b[1;32m    837\u001b[0m     start,\n\u001b[1;32m    838\u001b[0m     end,\n\u001b[1;32m    839\u001b[0m     nobs,\n\u001b[1;32m    840\u001b[0m     base_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index,\n\u001b[1;32m    841\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    842\u001b[0m     silent\u001b[39m=\u001b[39;49msilent,\n\u001b[1;32m    843\u001b[0m     index_none\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index_none,\n\u001b[1;32m    844\u001b[0m     index_generated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index_generated,\n\u001b[1;32m    845\u001b[0m     data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata,\n\u001b[1;32m    846\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/tsa/base/tsa_model.py:362\u001b[0m, in \u001b[0;36mget_prediction_index\u001b[0;34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[0m\n\u001b[1;32m    358\u001b[0m     start, _, start_oos \u001b[39m=\u001b[39m get_index_label_loc(\n\u001b[1;32m    359\u001b[0m         start, base_index, data\u001b[39m.\u001b[39mrow_labels\n\u001b[1;32m    360\u001b[0m     )\n\u001b[1;32m    361\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 362\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `start` argument could not be matched to a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m location related to the index of the data.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m     )\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     end \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(start, \u001b[39mlen\u001b[39m(base_index) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'The `start` argument could not be matched to a location related to the index of the data.'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "# # 데이터 로드\n",
    "# df = pd.read_csv(\"/Users/ksy/문서/공모전/제3회_민원데이터분석경진대회/code/pages/민원데이터_사고일자통합.csv\",encoding=\"utf-8\")\n",
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# # ADDRESS와 사고 유형 리스트 생성\n",
    "# addresses = df['ADDRESS'].unique()\n",
    "# accident_types = ['꼬리물기', '불법유턴', '불법좌회전', '신호위반', '역주행', '정지선침범', '중앙선침범', '지정차로위반', '진로변경방법위반']\n",
    "\n",
    "# # 결과를 저장할 빈 데이터프레임 생성\n",
    "# future_df = pd.DataFrame()\n",
    "\n",
    "# for address in addresses:\n",
    "#     for accident_type in accident_types:\n",
    "#         temp_df = df[df['ADDRESS'] == address][['date', accident_type]].set_index('date').sort_index()\n",
    "#         model = ARIMA(temp_df, order=(1, 0, 0)) # p=1, d=0, q=0으로 설정. 실제 사용시 최적 파라미터를 찾아야 함.\n",
    "#         model_fit = model.fit()\n",
    "        \n",
    "#         future_dates=[temp_df.index[-1] + DateOffset(days=x) for x in range(1,366)]\n",
    "#         future_dates_df=pd.DataFrame(index=future_dates[0:],columns=temp_df.columns)\n",
    "        \n",
    "#         future_prediction=pd.concat([temp_df,future_dates_df])\n",
    "        \n",
    "#         future_prediction[accident_type]=model_fit.predict(start='2023-01-01', end='2023-12-31')\n",
    "        \n",
    "#         # ADDRESS와 사고 유형 칼럼 추가 및 결합\n",
    "#         future_prediction.reset_index(inplace=True)\n",
    "#         future_prediction.rename(columns={'index': 'date'}, inplace=True)\n",
    "#         future_prediction.insert(1,'ADDRESS',[address]*len(future_prediction))\n",
    "#         future_prediction.insert(2,'신고유형',[accident_type]*len(future_prediction))\n",
    "        \n",
    "#         # 결과 데이터프레임과 결합\n",
    "#         if len(future_df)==0:\n",
    "#             future_df=future_prediction.copy()\n",
    "            \n",
    "#         else:\n",
    "#             future_df=pd.concat([future_df,future_prediction],ignore_index=True)\n",
    "\n",
    "# # 결과 저장\n",
    "# future_df.to_csv('prediction_2023.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
